{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import * \n",
    "from keras.layers import *\n",
    "import itertools\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "from keras.activations import *\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = [128,128,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive = zipfile.ZipFile(\"train.zip\")\n",
    "labels = pd.read_csv(\"labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128 at 0x22382DAB358>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open(archive.open(archive.filelist[1])).resize([128,128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_labels = list(set([i for i in labels[\"breed\"].values]))\n",
    "b2i = dict(zip(list_labels, itertools.count()))\n",
    "i2b = dict(zip(itertools.count(), list_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2i[\"english_foxhound\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'great_dane'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2b = dict(zip(labels[\"id\"], labels[\"breed\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye = np.eye(len(list_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ZipInfo filename='train/000bec180eb18c7604dcecc8fe0dba07.jpg' compress_type=deflate filemode='-rw-r--r--' external_attr=0x4000 file_size=54775 compress_size=54651>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archive.filelist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pics(adrs):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in adrs:\n",
    "        if \"jpg\" in i.filename :\n",
    "            intg = b2i[id2b[i.filename[i.filename.index(\"/\")+1:i.filename.index(\".\")]]]\n",
    "            y1 = eye[intg:intg+1,:]\n",
    "            x1 = np.array(Image.open(archive.open(i.filename)).resize(shape[:-1])).astype(np.float32)\n",
    "            X.append(x1)\n",
    "            y.append(y1)\n",
    "    X = (np.array(X)/ 255.0).astype(np.float32) \n",
    "    y = np.array(y).astype(np.float32)\n",
    "    return X, y.reshape((-1, len(list_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(batch_size, list1):\n",
    "    current_batch = 0\n",
    "    while True :\n",
    "        \n",
    "        end = min(current_batch + batch_size, len(list1))\n",
    "        \n",
    "        X, y = get_pics(list1[current_batch:end])\n",
    "        \n",
    "        current_batch += batch_size\n",
    "        if not (current_batch < len(list1)):\n",
    "            current_batch = 0\n",
    "            \n",
    "        yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=archive.filelist\n",
    "np.random.shuffle(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(batchNorm = True):\n",
    "    in1 = Input(shape)\n",
    "#     128*128*3 = 49,152\n",
    "    X = Conv2D(32, [5,5], strides=[2,2], padding=\"SAME\", activation=relu)(in1)\n",
    "#     64,64,32\n",
    "    X = Conv2D(32, [5,5], strides=[2,2], padding=\"SAME\", activation=relu)(X)\n",
    "    if batchNorm :\n",
    "        X = BatchNormalization()(X)\n",
    "#     32,32,32\n",
    "    X = Conv2D(64, [5,5], strides=[2,2], padding=\"SAME\", activation=relu)(X)    \n",
    "    if batchNorm :\n",
    "        X = BatchNormalization()(X)\n",
    "#     16*16*64\n",
    "    X = Conv2D(64, [5,5], strides=[2,2], padding=\"SAME\", activation=relu)(X)\n",
    "    if batchNorm :\n",
    "        X = BatchNormalization()(X)\n",
    "#     8*8*64\n",
    "    X = Conv2D(128, [5,5], strides=[2,2], padding=\"SAME\", activation=relu)(X)\n",
    "    if batchNorm :\n",
    "        X = BatchNormalization()(X)\n",
    "#     4*4*128 = 2048\n",
    "\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1024, activation=relu)(X)\n",
    "    X = Dense(256, activation=relu)(X)\n",
    "    X = Dense(len(list_labels), activation=softmax)(X)\n",
    "    \n",
    "    \n",
    "    model = Model(in1, X)\n",
    "    \n",
    "    \n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_doesnt_work_well = get_model(batchNorm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        2432      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 2,779,288\n",
      "Trainable params: 2,778,712\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(keras.optimizers.adam(lr=1e-3), loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"])\n",
    "model_doesnt_work_well.compile(keras.optimizers.adam(lr=1e-3), loss=keras.losses.categorical_crossentropy, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1024/1024 [==============================] - 3s 3ms/step - loss: 4.7880 - acc: 0.0078\n",
      "Epoch 2/30\n",
      "1024/1024 [==============================] - 1s 666us/step - loss: 4.7714 - acc: 0.0098\n",
      "Epoch 3/30\n",
      "1024/1024 [==============================] - 1s 677us/step - loss: 4.7526 - acc: 0.0068\n",
      "Epoch 4/30\n",
      "1024/1024 [==============================] - 1s 673us/step - loss: 4.7382 - acc: 0.0117\n",
      "Epoch 5/30\n",
      "1024/1024 [==============================] - 1s 666us/step - loss: 4.7322 - acc: 0.0068\n",
      "Epoch 6/30\n",
      "1024/1024 [==============================] - 1s 690us/step - loss: 4.7299 - acc: 0.0107\n",
      "Epoch 7/30\n",
      "1024/1024 [==============================] - 1s 694us/step - loss: 4.7250 - acc: 0.0098\n",
      "Epoch 8/30\n",
      "1024/1024 [==============================] - 1s 668us/step - loss: 4.7245 - acc: 0.0088\n",
      "Epoch 9/30\n",
      "1024/1024 [==============================] - 1s 685us/step - loss: 4.7261 - acc: 0.0146\n",
      "Epoch 10/30\n",
      "1024/1024 [==============================] - 1s 688us/step - loss: 4.7711 - acc: 0.0098\n",
      "Epoch 11/30\n",
      "1024/1024 [==============================] - 1s 691us/step - loss: 4.7323 - acc: 0.0127\n",
      "Epoch 12/30\n",
      "1024/1024 [==============================] - 1s 680us/step - loss: 4.7280 - acc: 0.0117\n",
      "Epoch 13/30\n",
      "1024/1024 [==============================] - 1s 692us/step - loss: 4.7235 - acc: 0.0127\n",
      "Epoch 14/30\n",
      "1024/1024 [==============================] - 1s 698us/step - loss: 4.7246 - acc: 0.0107\n",
      "Epoch 15/30\n",
      "1024/1024 [==============================] - 1s 689us/step - loss: 4.7233 - acc: 0.0117\n",
      "Epoch 16/30\n",
      "1024/1024 [==============================] - 1s 689us/step - loss: 4.7211 - acc: 0.0117\n",
      "Epoch 17/30\n",
      "1024/1024 [==============================] - 1s 692us/step - loss: 4.7211 - acc: 0.0078\n",
      "Epoch 18/30\n",
      "1024/1024 [==============================] - 1s 682us/step - loss: 4.7217 - acc: 0.0127\n",
      "Epoch 19/30\n",
      "1024/1024 [==============================] - 1s 695us/step - loss: 4.7200 - acc: 0.0117\n",
      "Epoch 20/30\n",
      "1024/1024 [==============================] - 1s 694us/step - loss: 4.7219 - acc: 0.0156\n",
      "Epoch 21/30\n",
      "1024/1024 [==============================] - 1s 685us/step - loss: 4.7197 - acc: 0.0137\n",
      "Epoch 22/30\n",
      "1024/1024 [==============================] - 1s 681us/step - loss: 4.7203 - acc: 0.0156 0s - loss: 4.7342 - a\n",
      "Epoch 23/30\n",
      "1024/1024 [==============================] - 1s 691us/step - loss: 4.7202 - acc: 0.0137\n",
      "Epoch 24/30\n",
      "1024/1024 [==============================] - 1s 697us/step - loss: 4.7189 - acc: 0.0127\n",
      "Epoch 25/30\n",
      "1024/1024 [==============================] - 1s 696us/step - loss: 4.7202 - acc: 0.0127\n",
      "Epoch 26/30\n",
      "1024/1024 [==============================] - 1s 693us/step - loss: 4.7199 - acc: 0.0156\n",
      "Epoch 27/30\n",
      "1024/1024 [==============================] - 1s 688us/step - loss: 4.7190 - acc: 0.0117\n",
      "Epoch 28/30\n",
      "1024/1024 [==============================] - 1s 692us/step - loss: 4.7197 - acc: 0.0156\n",
      "Epoch 29/30\n",
      "1024/1024 [==============================] - 1s 684us/step - loss: 4.7196 - acc: 0.0146\n",
      "Epoch 30/30\n",
      "1024/1024 [==============================] - 1s 688us/step - loss: 4.7201 - acc: 0.0156\n",
      "Epoch 1/30\n",
      "1024/1024 [==============================] - 1s 695us/step - loss: 4.7198 - acc: 0.0127\n",
      "Epoch 2/30\n",
      "1024/1024 [==============================] - 1s 700us/step - loss: 4.7185 - acc: 0.0137\n",
      "Epoch 3/30\n",
      "1024/1024 [==============================] - 1s 680us/step - loss: 4.7203 - acc: 0.0127 0s - loss: 4.7167 - acc: 0.013\n",
      "Epoch 4/30\n",
      "1024/1024 [==============================] - 1s 696us/step - loss: 4.7191 - acc: 0.0059\n",
      "Epoch 5/30\n",
      "1024/1024 [==============================] - 1s 672us/step - loss: 4.7184 - acc: 0.0127\n",
      "Epoch 6/30\n",
      "1024/1024 [==============================] - 1s 693us/step - loss: 4.7190 - acc: 0.0156\n",
      "Epoch 7/30\n",
      "1024/1024 [==============================] - 1s 700us/step - loss: 4.7183 - acc: 0.0137\n",
      "Epoch 8/30\n",
      "1024/1024 [==============================] - 1s 677us/step - loss: 4.7187 - acc: 0.0156\n",
      "Epoch 9/30\n",
      "1024/1024 [==============================] - 1s 697us/step - loss: 4.7188 - acc: 0.0117\n",
      "Epoch 10/30\n",
      "1024/1024 [==============================] - 1s 697us/step - loss: 4.7186 - acc: 0.0098\n",
      "Epoch 11/30\n",
      "1024/1024 [==============================] - 1s 691us/step - loss: 4.7174 - acc: 0.0127\n",
      "Epoch 12/30\n",
      "1024/1024 [==============================] - 1s 694us/step - loss: 4.7184 - acc: 0.0156\n",
      "Epoch 13/30\n",
      "1024/1024 [==============================] - 1s 689us/step - loss: 4.7176 - acc: 0.0146\n",
      "Epoch 14/30\n",
      "1024/1024 [==============================] - 1s 690us/step - loss: 4.7175 - acc: 0.0127\n",
      "Epoch 15/30\n",
      "1024/1024 [==============================] - 1s 687us/step - loss: 4.7181 - acc: 0.0146\n",
      "Epoch 16/30\n",
      "1024/1024 [==============================] - 1s 694us/step - loss: 4.7186 - acc: 0.0117\n",
      "Epoch 17/30\n",
      "1024/1024 [==============================] - 1s 694us/step - loss: 4.7176 - acc: 0.0137\n",
      "Epoch 18/30\n",
      "1024/1024 [==============================] - 1s 680us/step - loss: 4.7189 - acc: 0.0156\n",
      "Epoch 19/30\n",
      "1024/1024 [==============================] - 1s 693us/step - loss: 4.7174 - acc: 0.0127\n",
      "Epoch 20/30\n",
      "1024/1024 [==============================] - 1s 692us/step - loss: 4.7175 - acc: 0.0156\n",
      "Epoch 21/30\n",
      "1024/1024 [==============================] - 1s 701us/step - loss: 4.7179 - acc: 0.0107\n",
      "Epoch 22/30\n",
      "1024/1024 [==============================] - 1s 685us/step - loss: 4.7173 - acc: 0.0127\n",
      "Epoch 23/30\n",
      "1024/1024 [==============================] - 1s 688us/step - loss: 4.7177 - acc: 0.0146\n",
      "Epoch 24/30\n",
      "1024/1024 [==============================] - 1s 730us/step - loss: 4.7172 - acc: 0.0137\n",
      "Epoch 25/30\n",
      "1024/1024 [==============================] - 1s 680us/step - loss: 4.7173 - acc: 0.0156\n",
      "Epoch 26/30\n",
      "1024/1024 [==============================] - 1s 687us/step - loss: 4.7176 - acc: 0.0166\n",
      "Epoch 27/30\n",
      "1024/1024 [==============================] - 1s 697us/step - loss: 4.7181 - acc: 0.0156\n",
      "Epoch 28/30\n",
      "1024/1024 [==============================] - 1s 676us/step - loss: 4.7173 - acc: 0.0127\n",
      "Epoch 29/30\n",
      "1024/1024 [==============================] - 1s 683us/step - loss: 4.7178 - acc: 0.0137\n",
      "Epoch 30/30\n",
      "1024/1024 [==============================] - 1s 700us/step - loss: 4.7170 - acc: 0.0107\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    for X, y in get_data(1024, list1):\n",
    "        model_doesnt_work_well.fit(X, y, batch_size=32, epochs=30)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 4s 1ms/step - loss: 4.8285 - acc: 0.0186\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 3s 742us/step - loss: 4.5857 - acc: 0.0349\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 3s 738us/step - loss: 4.3626 - acc: 0.0566\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 3s 739us/step - loss: 4.0628 - acc: 0.0881\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 3s 744us/step - loss: 4.5436 - acc: 0.0349\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 3s 735us/step - loss: 4.1820 - acc: 0.0732 \n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 3s 739us/step - loss: 3.7248 - acc: 0.1345\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 3s 739us/step - loss: 3.0184 - acc: 0.2749\n",
      "Epoch 1/4\n",
      "2030/2030 [==============================] - 2s 764us/step - loss: 4.5465 - acc: 0.0384\n",
      "Epoch 2/4\n",
      "2030/2030 [==============================] - 2s 743us/step - loss: 3.5992 - acc: 0.1552\n",
      "Epoch 3/4\n",
      "2030/2030 [==============================] - 2s 747us/step - loss: 2.5250 - acc: 0.3916\n",
      "Epoch 4/4\n",
      "2030/2030 [==============================] - 2s 755us/step - loss: 1.2650 - acc: 0.7020\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 3s 751us/step - loss: 4.3578 - acc: 0.0618\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 3s 749us/step - loss: 3.3055 - acc: 0.2075\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 3s 745us/step - loss: 2.0690 - acc: 0.4827\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 3s 745us/step - loss: 0.8237 - acc: 0.7917\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 3s 756us/step - loss: 3.7407 - acc: 0.1389\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 3s 746us/step - loss: 1.6904 - acc: 0.5657\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 3s 746us/step - loss: 0.5409 - acc: 0.8633\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 3s 748us/step - loss: 0.1045 - acc: 0.9846\n",
      "Epoch 1/4\n",
      "2030/2030 [==============================] - 2s 774us/step - loss: 3.1573 - acc: 0.2690\n",
      "Epoch 2/4\n",
      "2030/2030 [==============================] - 2s 743us/step - loss: 0.5194 - acc: 0.8650\n",
      "Epoch 3/4\n",
      "2030/2030 [==============================] - 2s 749us/step - loss: 0.0580 - acc: 0.9921\n",
      "Epoch 4/4\n",
      "2030/2030 [==============================] - 1s 737us/step - loss: 0.0093 - acc: 0.9995\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 3s 749us/step - loss: 2.0422 - acc: 0.4722\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 3s 751us/step - loss: 0.2595 - acc: 0.9341\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 3s 744us/step - loss: 0.0263 - acc: 0.9966\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 3s 743us/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 3s 749us/step - loss: 1.4530 - acc: 0.5986\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 3s 743us/step - loss: 0.1528 - acc: 0.9617\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 3s 748us/step - loss: 0.0203 - acc: 0.9973\n",
      "Epoch 4/4\n",
      "4096/4096 [==============================] - 3s 744us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 1/4\n",
      "2030/2030 [==============================] - 2s 765us/step - loss: 1.2918 - acc: 0.6438\n",
      "Epoch 2/4\n",
      "2030/2030 [==============================] - 2s 755us/step - loss: 0.1295 - acc: 0.9670\n",
      "Epoch 3/4\n",
      "2030/2030 [==============================] - 2s 758us/step - loss: 0.0120 - acc: 0.9990\n",
      "Epoch 4/4\n",
      "2030/2030 [==============================] - 2s 749us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 1/4\n",
      "4096/4096 [==============================] - 3s 756us/step - loss: 1.0101 - acc: 0.7070\n",
      "Epoch 2/4\n",
      "4096/4096 [==============================] - 3s 744us/step - loss: 0.1146 - acc: 0.9685\n",
      "Epoch 3/4\n",
      "4096/4096 [==============================] - 3s 750us/step - loss: 0.0219 - acc: 0.9949\n",
      "Epoch 4/4\n",
      "4000/4096 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9995"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-0691049d2705>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4096\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m#     if i % 5 == 0 :\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    183\u001b[0m                         \u001b[1;31m# Do not slice the training phase flag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                         ins_batch = slice_arrays(\n\u001b[1;32m--> 185\u001b[1;33m                             ins[:-1], batch_ids) + [ins[-1]]\n\u001b[0m\u001b[0;32m    186\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    521\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    521\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "del(X)\n",
    "del(y)\n",
    "del(model_doesnt_work_well)\n",
    "tic = time.time()\n",
    "for i in range(epochs):\n",
    "    for X, y in get_data(4096, list1):\n",
    "        model.fit(X, y, batch_size=32, epochs=4)\n",
    "#     if i % 5 == 0 :\n",
    "    toc = time.time()\n",
    "    tic = toc\n",
    "    print(toc - tic)\n",
    "    print(\"epochs:\",i)\n",
    "    print(model.evaluate(X, y)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "4096/4096 [==============================] - 3s 756us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 1/1\n",
      "4096/4096 [==============================] - 3s 745us/step - loss: 0.9662 - acc: 0.7234 1s - loss: 1.06\n",
      "Epoch 1/1\n",
      "2030/2030 [==============================] - 2s 757us/step - loss: 0.8818 - acc: 0.7507\n",
      "Epoch 1/1\n",
      "4096/4096 [==============================] - 3s 743us/step - loss: 0.5366 - acc: 0.8479\n",
      "Epoch 1/1\n",
      "4096/4096 [==============================] - 3s 745us/step - loss: 0.4987 - acc: 0.8567\n",
      "Epoch 1/1\n",
      "2030/2030 [==============================] - 2s 763us/step - loss: 0.3517 - acc: 0.8951\n",
      "Epoch 1/1\n",
      "4096/4096 [==============================] - 3s 731us/step - loss: 0.2710 - acc: 0.9204\n",
      "Epoch 1/1\n",
      "4096/4096 [==============================] - 3s 769us/step - loss: 0.2027 - acc: 0.9441\n",
      "Epoch 1/1\n",
      "2030/2030 [==============================] - 2s 760us/step - loss: 0.1733 - acc: 0.9542\n",
      "Epoch 1/1\n",
      "4096/4096 [==============================] - 3s 731us/step - loss: 0.1517 - acc: 0.9565\n",
      "Epoch 1/1\n",
      "4096/4096 [==============================] - 3s 730us/step - loss: 0.1224 - acc: 0.9673\n",
      "Epoch 1/1\n",
      "2030/2030 [==============================] - 1s 736us/step - loss: 0.0946 - acc: 0.9783\n",
      "Epoch 1/1\n",
      "4096/4096 [==============================] - 3s 733us/step - loss: 0.1010 - acc: 0.9731\n",
      "Epoch 1/1\n",
      "4096/4096 [==============================] - 3s 731us/step - loss: 0.0764 - acc: 0.9792 2\n",
      "Epoch 1/1\n",
      "2030/2030 [==============================] - 2s 768us/step - loss: 0.0669 - acc: 0.9842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-39-f5b9cf209dc4>\", line 6, in <module>\n",
      "    for X, y in get_data(4096, list1):\n",
      "  File \"<ipython-input-13-37dd0ce8ae59>\", line 7, in get_data\n",
      "    X, y = get_pics(list1[current_batch:end])\n",
      "  File \"<ipython-input-12-c0ad550e55bc>\", line 8, in get_pics\n",
      "    x1 = np.array(Image.open(archive.open(i.filename)).resize(shape[:-1])).astype(np.float32)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\", line 1747, in resize\n",
      "    self.load()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "OSError: [WinError 123] The filename, directory name, or volume label syntax is incorrect: '<ipython-input-13-37dd0ce8ae59>'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1445, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 165, in findsource\n",
      "    file = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "del(X)\n",
    "del(y)\n",
    "tic = time.time()\n",
    "for i in range(epochs):\n",
    "    for X, y in get_data(4096, list1):\n",
    "        model.fit(X, y, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
      "102858752/102853048 [==============================] - 51s 0us/step\n"
     ]
    }
   ],
   "source": [
    "shape = [224, 224, 3]\n",
    "# side note : let's talk about how to absorbe this models into our own models\n",
    "if \"resnet.h5\" in os.listdir():\n",
    "    print(\"loading model\")\n",
    "    model_res_net = load_model(\"resnet.h5\")\n",
    "else :\n",
    "    model_res_net = keras.applications.resnet50.ResNet50(include_top=True, weights='imagenet', input_shape=tuple(shape))\n",
    "    model_res_net.save(\"resnet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'fc1000_1/Softmax:0' shape=(?, 1000) dtype=float32>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_res_net.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Flatten at 0x225a90d7b70>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_res_net.layers[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_final_from_downloaded(model):\n",
    "    output = model_res_net.layers[-2].output\n",
    "    in1 = model.input\n",
    "    X = Dense(1024, activation=relu)(output)\n",
    "    X = Dense(len(list_labels), activation=softmax)(X)\n",
    "    \n",
    "    newModel = Model(in1, X)\n",
    "    return newModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = get_model_final_from_downloaded(model_res_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(keras.optimizers.adam(lr=1e-3), keras.losses.categorical_crossentropy, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 55, 55, 64)   0           activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 55, 55, 64)   4160        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 55, 55, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 55, 55, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 55, 55, 256)  16640       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 55, 55, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_36 (Add)                    (None, 55, 55, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 55, 55, 256)  0           add_36[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 55, 55, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 55, 55, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_37 (Add)                    (None, 55, 55, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 55, 55, 256)  0           add_37[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 55, 55, 64)   16448       activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 55, 55, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 55, 55, 64)   36928       activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 55, 55, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 55, 55, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 55, 55, 256)  16640       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 55, 55, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_38 (Add)                    (None, 55, 55, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 55, 55, 256)  0           add_38[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_39 (Add)                    (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 28, 28, 512)  0           add_39[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_40 (Add)                    (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 28, 28, 512)  0           add_40[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_41 (Add)                    (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 28, 28, 512)  0           add_41[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_42 (Add)                    (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 28, 28, 512)  0           add_42[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_43 (Add)                    (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 14, 14, 1024) 0           add_43[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_44 (Add)                    (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 14, 14, 1024) 0           add_44[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_45 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 14, 14, 1024) 0           add_45[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_46 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 14, 14, 1024) 0           add_46[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_47 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 14, 14, 1024) 0           add_47[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_48 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 14, 14, 1024) 0           add_48[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_49 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 7, 7, 2048)   0           add_49[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_50 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 7, 7, 2048)   0           add_50[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_51 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 7, 7, 2048)   0           add_51[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 1024)         2098176     flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 120)          123000      dense_21[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,808,888\n",
      "Trainable params: 25,755,768\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 4.5527 - acc: 0.0264\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 4.5717 - acc: 0.0264\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 4.5375 - acc: 0.0400\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 4.4946 - acc: 0.0371\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 4.5842 - acc: 0.0293\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 4.4766 - acc: 0.0420\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 4.4386 - acc: 0.0381\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 4.3864 - acc: 0.0381\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 15s 15ms/step - loss: 4.3536 - acc: 0.0489\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 15s 14ms/step - loss: 4.3728 - acc: 0.0497\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 4.2532 - acc: 0.0508\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 4.2726 - acc: 0.0527\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 4.2392 - acc: 0.0605\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 4.1580 - acc: 0.0615\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 4.2496 - acc: 0.0547\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 4.1820 - acc: 0.0762\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 4.1242 - acc: 0.0684\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 4.0734 - acc: 0.0615\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 4.0742 - acc: 0.0626\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 4.0826 - acc: 0.0705\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 4.0233 - acc: 0.0684\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 4.0398 - acc: 0.0674\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.9869 - acc: 0.0762\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.9398 - acc: 0.0859\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 4.0043 - acc: 0.0859\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.9495 - acc: 0.0811\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.9175 - acc: 0.0996\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.8625 - acc: 0.0869\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 3.8334 - acc: 0.0958\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 3.9086 - acc: 0.0924\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.8543 - acc: 0.0879\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.7941 - acc: 0.1045\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.8088 - acc: 0.0918\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.6905 - acc: 0.1201\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.8097 - acc: 0.0977\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.7743 - acc: 0.1182\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 15s 14ms/step - loss: 3.6714 - acc: 0.1250\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.6464 - acc: 0.1387\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 3.6734 - acc: 0.1251\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 3.7513 - acc: 0.1261\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.6147 - acc: 0.1221\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 15s 14ms/step - loss: 3.5687 - acc: 0.1406\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 15s 14ms/step - loss: 3.5791 - acc: 0.1309\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.4936 - acc: 0.1523\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.5915 - acc: 0.1299\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 15s 14ms/step - loss: 3.5187 - acc: 0.1436\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.4474 - acc: 0.1729\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.4701 - acc: 0.1436\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 3.3562 - acc: 0.1867\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 3.4624 - acc: 0.1678\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.3783 - acc: 0.1709\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.3357 - acc: 0.1836\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 15s 14ms/step - loss: 3.3022 - acc: 0.1670\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.2227 - acc: 0.1982\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 15s 14ms/step - loss: 3.3300 - acc: 0.1758\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.2679 - acc: 0.1758\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.1670 - acc: 0.2012\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.1959 - acc: 0.1973\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 3.1414 - acc: 0.2131\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 3.1722 - acc: 0.2195\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 15s 14ms/step - loss: 3.1170 - acc: 0.2109\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.0149 - acc: 0.2461\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.0197 - acc: 0.2197\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 2.9367 - acc: 0.2559\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 3.1169 - acc: 0.2109\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 2.9455 - acc: 0.2617\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 2.8589 - acc: 0.2588\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 2.8840 - acc: 0.2656\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 2.7609 - acc: 0.2825\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 2.8207 - acc: 0.2661\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 2.7746 - acc: 0.2783\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 2.7563 - acc: 0.2998\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 2.6473 - acc: 0.2939\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 2.5085 - acc: 0.3301\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 15s 14ms/step - loss: 2.7694 - acc: 0.2666\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 2.5780 - acc: 0.3330\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 2.4867 - acc: 0.3604\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 2.5099 - acc: 0.3311\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 2.4789 - acc: 0.3421\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 2.4473 - acc: 0.3515\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 2.3409 - acc: 0.3916\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 2.4047 - acc: 0.3857\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 2.2960 - acc: 0.3848\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - 14s 14ms/step - loss: 2.1354 - acc: 0.4248\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 2.3212 - acc: 0.3662\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 2.1535 - acc: 0.4307\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 2.0811 - acc: 0.4404\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 2.1153 - acc: 0.4072\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 1.8930 - acc: 0.4868\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 1.9738 - acc: 0.4727\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.9581 - acc: 0.4590\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.9081 - acc: 0.4775\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.7655 - acc: 0.5156\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.6575 - acc: 0.5381\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.9135 - acc: 0.4756\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.7586 - acc: 0.5254\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.5953 - acc: 0.5537\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.5927 - acc: 0.5469\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 1.4868 - acc: 0.5855\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 1.5499 - acc: 0.5690\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.4990 - acc: 0.5928\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.4560 - acc: 0.5889\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.3493 - acc: 0.6064\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.2041 - acc: 0.6650\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.3187 - acc: 0.6279\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.2180 - acc: 0.6611\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.1273 - acc: 0.6855\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.1457 - acc: 0.6787\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 15s 14ms/step - loss: 0.9436 - acc: 0.7410\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 1.0352 - acc: 0.7031\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.1098 - acc: 0.6992\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 1.0078 - acc: 0.7246\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.8932 - acc: 0.7422\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.7859 - acc: 0.7773\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.8570 - acc: 0.7666\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.7825 - acc: 0.7871\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.6636 - acc: 0.8271\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.7756 - acc: 0.7705\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.7275 - acc: 0.7918\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.6804 - acc: 0.8054\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.7078 - acc: 0.7939\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.7267 - acc: 0.7861\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.6319 - acc: 0.8271\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.5431 - acc: 0.8545\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.5027 - acc: 0.8711\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.4899 - acc: 0.8711\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.4767 - acc: 0.8750\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.4376 - acc: 0.8838\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.4372 - acc: 0.8817\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.4137 - acc: 0.8848\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.4245 - acc: 0.8799\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.4717 - acc: 0.8672\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 15s 14ms/step - loss: 0.4027 - acc: 0.8896\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.3481 - acc: 0.9111\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.3599 - acc: 0.9072\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.3426 - acc: 0.9160\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.3133 - acc: 0.9238\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2578 - acc: 0.9395\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.3408 - acc: 0.9140\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.3252 - acc: 0.9106\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.3685 - acc: 0.8955\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.3686 - acc: 0.9072\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.3142 - acc: 0.9160\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2399 - acc: 0.9473\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2410 - acc: 0.9502\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2285 - acc: 0.9375\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1955 - acc: 0.9512\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2745 - acc: 0.9170\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.2206 - acc: 0.9384\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.2251 - acc: 0.9454\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2719 - acc: 0.9238\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2257 - acc: 0.9453\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2132 - acc: 0.9346\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2175 - acc: 0.9434\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2135 - acc: 0.9453\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1951 - acc: 0.9531\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1709 - acc: 0.9570\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1740 - acc: 0.9600\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.1632 - acc: 0.9570\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.1200 - acc: 0.9712\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1815 - acc: 0.9570\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1624 - acc: 0.9551\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1761 - acc: 0.9521\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1770 - acc: 0.9541\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1181 - acc: 0.9736\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1453 - acc: 0.9668\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1294 - acc: 0.9678\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1457 - acc: 0.9600\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.1446 - acc: 0.9609\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.1815 - acc: 0.9464\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1715 - acc: 0.9541\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.2031 - acc: 0.9531\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1549 - acc: 0.9570\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1469 - acc: 0.9688\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1391 - acc: 0.9727\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1400 - acc: 0.9707\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1192 - acc: 0.9775\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0935 - acc: 0.9775\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.1302 - acc: 0.9668\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.1144 - acc: 0.9732\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1688 - acc: 0.9551\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1874 - acc: 0.9414\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1466 - acc: 0.9629\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1531 - acc: 0.9590\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0979 - acc: 0.9785\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1295 - acc: 0.9707\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1205 - acc: 0.9697\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1205 - acc: 0.9707\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0978 - acc: 0.9795\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.1560 - acc: 0.9523\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1490 - acc: 0.9619\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1484 - acc: 0.9609\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1255 - acc: 0.9697\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1539 - acc: 0.9629\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0944 - acc: 0.9785\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1279 - acc: 0.9678\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1147 - acc: 0.9688\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1135 - acc: 0.9707\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.1129 - acc: 0.9756\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.1144 - acc: 0.9682\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1282 - acc: 0.9697\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 15s 14ms/step - loss: 0.1281 - acc: 0.9668\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1539 - acc: 0.9648\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1620 - acc: 0.9570\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1740 - acc: 0.9580\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1666 - acc: 0.9629\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1704 - acc: 0.9482\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1407 - acc: 0.9609\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.1359 - acc: 0.9619\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.1252 - acc: 0.9722\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1194 - acc: 0.9668\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1124 - acc: 0.9707\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1043 - acc: 0.9766\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 15s 14ms/step - loss: 0.1123 - acc: 0.9775\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1239 - acc: 0.9678\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0954 - acc: 0.9746\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0944 - acc: 0.9795\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0718 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0804 - acc: 0.9814\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0805 - acc: 0.9801\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0962 - acc: 0.9697\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1454 - acc: 0.9600\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1052 - acc: 0.9756\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1116 - acc: 0.9697\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0919 - acc: 0.9756\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0943 - acc: 0.9824\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0708 - acc: 0.9814\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0776 - acc: 0.9795\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0771 - acc: 0.9785\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0594 - acc: 0.9861\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0786 - acc: 0.9824\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0642 - acc: 0.9824\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1050 - acc: 0.9746\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1154 - acc: 0.9648\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1052 - acc: 0.9766\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 15s 14ms/step - loss: 0.1075 - acc: 0.9717\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0801 - acc: 0.9814\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1198 - acc: 0.9678\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0868 - acc: 0.9795\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0645 - acc: 0.9831\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0855 - acc: 0.9795\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0903 - acc: 0.9727\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1141 - acc: 0.9648\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1173 - acc: 0.9707\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0872 - acc: 0.9756\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0824 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0891 - acc: 0.9707\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0696 - acc: 0.9824\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0625 - acc: 0.9824\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0982 - acc: 0.9722\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1234 - acc: 0.9658\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1251 - acc: 0.9639\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1236 - acc: 0.9678\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1444 - acc: 0.9609\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1116 - acc: 0.9688\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0777 - acc: 0.9795\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0775 - acc: 0.9814\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0475 - acc: 0.9893\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0563 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0591 - acc: 0.9871\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0771 - acc: 0.9727\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0726 - acc: 0.9814\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0972 - acc: 0.9717\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0685 - acc: 0.9795\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1195 - acc: 0.9658\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1152 - acc: 0.9746\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0926 - acc: 0.9727\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0821 - acc: 0.9775\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0848 - acc: 0.9785\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0673 - acc: 0.9851\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0767 - acc: 0.9736\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0786 - acc: 0.9727\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0736 - acc: 0.9824\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0971 - acc: 0.9717\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1042 - acc: 0.9688\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0793 - acc: 0.9814\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0618 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0718 - acc: 0.9775\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0950 - acc: 0.9717\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.1262 - acc: 0.9603\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1305 - acc: 0.9580\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1306 - acc: 0.9600\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1271 - acc: 0.9580\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1066 - acc: 0.9707\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0903 - acc: 0.9756\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0801 - acc: 0.9756\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0701 - acc: 0.9834\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0652 - acc: 0.9893\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0669 - acc: 0.9804\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0758 - acc: 0.9772\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0511 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0457 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0565 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0514 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0583 - acc: 0.9824\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0634 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0599 - acc: 0.9834\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0538 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0734 - acc: 0.9804\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0845 - acc: 0.9752\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0804 - acc: 0.9785\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0791 - acc: 0.9717\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1033 - acc: 0.9629\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1036 - acc: 0.9736\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0932 - acc: 0.9766\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0942 - acc: 0.9707\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0867 - acc: 0.9746\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0735 - acc: 0.9766\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0570 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0558 - acc: 0.9811\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0751 - acc: 0.9766\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0930 - acc: 0.9746\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0917 - acc: 0.9697\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0561 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0416 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0541 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0447 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0571 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0678 - acc: 0.9785\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0782 - acc: 0.9791\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 15s 14ms/step - loss: 0.0569 - acc: 0.9824\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0566 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0601 - acc: 0.9834\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0836 - acc: 0.9795\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0516 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0418 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0520 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0955 - acc: 0.9746\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0987 - acc: 0.9756\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.1029 - acc: 0.9672\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0533 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0501 - acc: 0.9844\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0536 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0701 - acc: 0.9766\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0521 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0731 - acc: 0.9795\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1000 - acc: 0.9785\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0836 - acc: 0.9717\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0970 - acc: 0.9717\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0521 - acc: 0.9861\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0378 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0617 - acc: 0.9834\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0710 - acc: 0.9824\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0561 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0677 - acc: 0.9795\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0758 - acc: 0.9824\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0533 - acc: 0.9814\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0719 - acc: 0.9795\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0690 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0750 - acc: 0.9811\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0626 - acc: 0.9814\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0682 - acc: 0.9805\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0541 - acc: 0.9834\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0582 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0700 - acc: 0.9795\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0757 - acc: 0.9785\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0690 - acc: 0.9785\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0579 - acc: 0.9795\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0801 - acc: 0.9785\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0755 - acc: 0.9752\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0839 - acc: 0.9756\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0824 - acc: 0.9785\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0540 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0734 - acc: 0.9756\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0503 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0647 - acc: 0.9805\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0562 - acc: 0.9834\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0400 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0489 - acc: 0.9834\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0434 - acc: 0.9841\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0626 - acc: 0.9775\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0637 - acc: 0.9775\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0905 - acc: 0.9727\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0872 - acc: 0.9766\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0630 - acc: 0.9824\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0675 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0717 - acc: 0.9795\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0649 - acc: 0.9834\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0374 - acc: 0.9922\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0528 - acc: 0.9851\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0413 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0519 - acc: 0.9834\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0460 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0326 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0359 - acc: 0.9922\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0448 - acc: 0.9922\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0271 - acc: 0.9961\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0396 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0442 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0475 - acc: 0.9871\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0422 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0784 - acc: 0.9834\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0644 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0536 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0418 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0760 - acc: 0.9775\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0935 - acc: 0.9668\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0588 - acc: 0.9824\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0491 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0351 - acc: 0.9921\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0426 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0391 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0394 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0384 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0316 - acc: 0.9922\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0587 - acc: 0.9814\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0875 - acc: 0.9756\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0745 - acc: 0.9785\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0688 - acc: 0.9795\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0618 - acc: 0.9821\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0911 - acc: 0.9707\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0986 - acc: 0.9727\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0780 - acc: 0.9805\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0793 - acc: 0.9756\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 15s 14ms/step - loss: 0.0778 - acc: 0.9746\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0528 - acc: 0.9814\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0510 - acc: 0.9834\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0400 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0334 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0417 - acc: 0.9871\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0453 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0550 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0377 - acc: 0.9893\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0573 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0290 - acc: 0.9961\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0368 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0312 - acc: 0.9922\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0365 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0229 - acc: 0.9941\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0462 - acc: 0.9901\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0229 - acc: 0.9941\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0198 - acc: 0.9941\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0499 - acc: 0.9893\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0437 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0439 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0360 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0232 - acc: 0.9951\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0344 - acc: 0.9893\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0341 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0414 - acc: 0.9911\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0302 - acc: 0.9932\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0512 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0669 - acc: 0.9805\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0721 - acc: 0.9766\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0782 - acc: 0.9736\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0627 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0740 - acc: 0.9766\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0542 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0393 - acc: 0.9932\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0530 - acc: 0.9831\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0678 - acc: 0.9805\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0510 - acc: 0.9834\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0543 - acc: 0.9805\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0353 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0278 - acc: 0.9922\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0567 - acc: 0.9834\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0407 - acc: 0.9893\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0279 - acc: 0.9932\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0342 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0382 - acc: 0.9921\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0302 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0229 - acc: 0.9922\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0523 - acc: 0.9834\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0782 - acc: 0.9795\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0386 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0580 - acc: 0.9814\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0347 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0649 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0564 - acc: 0.9824\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0319 - acc: 0.9901\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0420 - acc: 0.9893\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0268 - acc: 0.9932\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0390 - acc: 0.9893\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0310 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0586 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0451 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0363 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0266 - acc: 0.9941\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0160 - acc: 0.9971\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0253 - acc: 0.9921\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0394 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0459 - acc: 0.9922\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0563 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0697 - acc: 0.9795\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0707 - acc: 0.9775\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0643 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0316 - acc: 0.9922\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0457 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0522 - acc: 0.9834\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0692 - acc: 0.9791\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1044 - acc: 0.9668\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1292 - acc: 0.9668\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.1079 - acc: 0.9688\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0775 - acc: 0.9795\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0416 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0488 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0486 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0414 - acc: 0.9873\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0786 - acc: 0.9765\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0439 - acc: 0.9851\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0415 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0392 - acc: 0.9893\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0452 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0281 - acc: 0.9932\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0247 - acc: 0.9941\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0504 - acc: 0.9893\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0336 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0294 - acc: 0.9922\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0299 - acc: 0.9932\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0373 - acc: 0.9871\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0492 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0410 - acc: 0.9922\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0270 - acc: 0.9951\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0462 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0341 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0501 - acc: 0.9834\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0220 - acc: 0.9932\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0302 - acc: 0.9941\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0266 - acc: 0.9941\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0370 - acc: 0.9930\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0159 - acc: 0.9961\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0325 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0297 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0389 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0153 - acc: 0.9941\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0687 - acc: 0.9814\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0449 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0508 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0496 - acc: 0.9853\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0611 - acc: 0.9801\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0583 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0475 - acc: 0.9834\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0290 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0381 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0597 - acc: 0.9834\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0482 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0474 - acc: 0.9824\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0318 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0421 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0566 - acc: 0.9791\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0558 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0537 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0535 - acc: 0.9834\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0446 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0240 - acc: 0.9951\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0431 - acc: 0.9893\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0434 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0443 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0353 - acc: 0.9892\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0379 - acc: 0.9891\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0323 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0304 - acc: 0.9922\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0329 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0189 - acc: 0.9961\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0384 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0406 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0350 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0432 - acc: 0.9893\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0423 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0274 - acc: 0.9921\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0339 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0282 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0390 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0449 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0360 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0414 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0422 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0307 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0357 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0391 - acc: 0.9891\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0276 - acc: 0.9941\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0269 - acc: 0.9922\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0340 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0515 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0383 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0514 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0474 - acc: 0.9893\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0379 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0465 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0237 - acc: 0.9940\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0183 - acc: 0.9932\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0619 - acc: 0.9814\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0563 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0543 - acc: 0.9834\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0433 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0353 - acc: 0.9893\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0269 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0283 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0352 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0312 - acc: 0.9921\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0568 - acc: 0.9795\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0577 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0318 - acc: 0.9922\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0481 - acc: 0.9893\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0374 - acc: 0.9893\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0494 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0499 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0364 - acc: 0.9893\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0488 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0293 - acc: 0.9901\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0407 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0479 - acc: 0.9834\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0379 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0316 - acc: 0.9922\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0151 - acc: 0.9961\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0399 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0389 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0372 - acc: 0.9922\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0402 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0275 - acc: 0.9921\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0491 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0445 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0453 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0244 - acc: 0.9941\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0356 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0380 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0515 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0379 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0373 - acc: 0.9922\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0232 - acc: 0.9950\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0211 - acc: 0.9951\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0308 - acc: 0.9922\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0202 - acc: 0.9932\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0283 - acc: 0.9893\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0250 - acc: 0.9932\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0360 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0303 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0221 - acc: 0.9941\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0276 - acc: 0.9932\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0317 - acc: 0.9940\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0315 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0195 - acc: 0.9941\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0229 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0159 - acc: 0.9941\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0132 - acc: 0.9971\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0515 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0225 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0384 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0347 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0623 - acc: 0.9861\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0718 - acc: 0.9775\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0661 - acc: 0.9824\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0515 - acc: 0.9824\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0400 - acc: 0.9893\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0309 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0564 - acc: 0.9824\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0318 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0278 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0203 - acc: 0.9941\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0379 - acc: 0.9871\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0445 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0392 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0409 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0364 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0469 - acc: 0.9883\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0439 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0295 - acc: 0.9902\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0519 - acc: 0.9844\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0353 - acc: 0.9873\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0465 - acc: 0.9881\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0472 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0458 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0328 - acc: 0.9912\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0404 - acc: 0.9854\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0495 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0529 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0505 - acc: 0.9863\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0496 - acc: 0.9854\n",
      "Epoch 1/1\n",
      "1023/1023 [==============================] - 14s 14ms/step - loss: 0.0228 - acc: 0.9922\n",
      "Epoch 1/1\n",
      "1007/1007 [==============================] - 14s 14ms/step - loss: 0.0250 - acc: 0.9921\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0253 - acc: 0.9941\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 14s 14ms/step - loss: 0.0307 - acc: 0.9922\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 15s 14ms/step - loss: 0.0348 - acc: 0.9873\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-140-f36bae5d9d3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# del(y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-37dd0ce8ae59>\u001b[0m in \u001b[0;36mget_data\u001b[1;34m(batch_size, list1)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_batch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_pics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrent_batch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mcurrent_batch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-c0ad550e55bc>\u001b[0m in \u001b[0;36mget_pics\u001b[1;34m(adrs)\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mintg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb2i\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid2b\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meye\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mintg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mintg\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marchive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mresize\u001b[1;34m(self, size, resample, box)\u001b[0m\n\u001b[0;32m   1745\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGBa'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGBA'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1747\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1749\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m                             \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "del(X)\n",
    "del(y)\n",
    "for i in range(epochs):\n",
    "    for X, y in get_data(1024, list1):\n",
    "        new_model.fit(X, y, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
